{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 : \n",
    "**Given an unknown-lenght array of the form 1, 1, 1, ..., 1, 0, 0, ..., 0, ... (with 1s at\n",
    "the first places and 0s after this), and the interface function getElement(array A, int i)\n",
    "that returns the i-th element of the given array, describe an efficient algorithm to count the\n",
    "number of 1s.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to solve this problem with dichotomy. \n",
    "\n",
    "We can solve this problem by itering over the whole array and increment an integer. The time complexity of this simple solution  would be O(n). \n",
    "\n",
    "We can use dichotomy to find the solution in O(Logn) time. The idea is to find the last occurrence of 1 using Dichotomy : \n",
    "1. We split the array in two, getting the mid element. \n",
    "2. We test wether the mid element is the last 1 in the array. In that case, we return the mid index.\n",
    "3. If not and mid index element is 0, then we split the array and two and do the same on the left side of the array, else the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1s in the array : 8\n"
     ]
    }
   ],
   "source": [
    "array = [1,1,1,1,1,1,1,1,0,0,0,0]\n",
    "\n",
    "def getElement(array, i):\n",
    "    return array[i]\n",
    "\n",
    "# Returns number of 1's in array[low..high].\n",
    "def number_ones(array, low, high):\n",
    "    #If high < low then we have no 1s in the array\n",
    "    if high >= low:\n",
    "        \n",
    "        # get the middle index\n",
    "        mid = low + (high-low)//2\n",
    "         \n",
    "        # check if the element at mid index is 1\n",
    "        if getElement(array, mid)==1 :\n",
    "            #Check if the element at mid+1 is 0 or mid == high, if that's the case, return the index of mid\n",
    "            if (mid == high or getElement(array, mid+1)==0) :\n",
    "                return mid+1\n",
    "            \n",
    "            # If the element at mid index is not the last 1, we split the array and recur from the right side\n",
    "            else : \n",
    "                return number_ones(array, (mid+1), high)\n",
    "            \n",
    "        # else we recur from the left side\n",
    "        return number_ones(array, low, mid-1)\n",
    "     \n",
    "    return 0\n",
    "\n",
    "print(\"Number of 1s in the array :\", number_ones(array, 0, len(array)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 : \n",
    "**Given a set of all integers from 1 to N missing only one of them, identify which\n",
    "one is missing in an efficient way.**\n",
    "\n",
    "In the same way, we can use dichotomy to get a O(logn) time complexity. We will try to find the first index for which getElement(index) != index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array with missing 8 : \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "indexes :\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "array = list(np.arange(0,20))\n",
    "del array[8]\n",
    "print(\"array with missing 8 : \")\n",
    "print(array)\n",
    "print(\"indexes :\")\n",
    "print(list(np.arange(19)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing element in the array is : 5\n"
     ]
    }
   ],
   "source": [
    "# o(logn) complexity function that returns the missing element of a 1..N array. It uses Dichotomy and recursivity \n",
    "def missing_elt(array, low, high): \n",
    "    if high >= low:\n",
    "        mid = low + (high-low)//2\n",
    "        #check if mid element is different from mid index\n",
    "        if array[mid] != mid:\n",
    "            \n",
    "            #we check if it's the first one in the array, in that case, we return mid index\n",
    "            if array[mid-1] == mid-1 or mid==low:\n",
    "                return mid\n",
    "            else :\n",
    "            #Otherwise we recur from the left\n",
    "                return missing_elt(array, low, mid-1)\n",
    "        else:\n",
    "            return missing_elt(array, mid+1, high)\n",
    "    else: \n",
    "        return 'no missing element !'\n",
    "    \n",
    "    \n",
    "print(\"The missing element in the array is :\", missing_elt(array, 0, len(array)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 : \n",
    "** In Euroleague basketball competition the Performance Index Rating (PIR) is\n",
    "used to determine the MVP of each round. It is a statistical formula that uses the players’\n",
    "stats during each game, e.g. points, rebounds, assists, etc. The stats can be found in the\n",
    "GAME CENTER section of http://www.euroleague.net for the majority of the games in the\n",
    "last years.**\n",
    "\n",
    "\n",
    "**Assuming that we don’t know the actual PIR formula, what is your approach(es) in order\n",
    "to determine it? Please, give as many details as possible. **\n",
    "\n",
    "**For your consideration, the answer can be found here and the actual PIR formula is\n",
    "(Points + Rebounds + Assists + Steals + Blocks + Fouls Drawn) -\n",
    "(Missed FG + Missed FT + Turnovers + Shots Rejected + Fouls Committed)**\n",
    "\n",
    "\n",
    "**where FG stands for Field Goals and FT stands for Free Throws. ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this, we will first srap the stats and PIR of some players and then we will perform the reverse engineering to find the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's scrap all the stats of some players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only scrap the first page as we will have enough data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We create a dictionary of indexes used in the website :\n",
    "dico = {3 : \"points\", 9 : \"rebonds\", 10 : \"assists\", 11 : \"steals\", 13 : \"blocks\", 16 : \"fouls drown\",\\\n",
    "        4 : \"missed fg1\", 5 : \"missed fg2\", 6 : \"missed ft\", 12 : \"turnovers\", 14 : \"shots rejected\", 15 : \"fouls committed\", \\\n",
    "       17 : \"PIR\"}\n",
    "\n",
    "#We only scrap the first page\n",
    "results = requests.get(\"http://www.euroleague.net/main/statistics?mode=Leaders&entity=Players&seasonmode=Single&seasoncode=E2017&cat=Valuation&agg=Accumulated\")\n",
    "soup = BeautifulSoup(results.text, 'html.parser')\n",
    "df = pd.DataFrame(columns=dico.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "#We find all the links leading to specific players pages to get the stats and PIR\n",
    "for tr in soup.find(\"table\").findAll(\"tr\")[1:]:\n",
    "    res = requests.get(\"http://www.euroleague.net/\"+tr.findAll(\"td\")[1].find('a', href=True)[\"href\"])\n",
    "    player = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    for line in (player.findAll(\"table\")[1].findAll(\"tr\")):\n",
    "        if \"TotalFooter\" in str(line) or \"AverageFooter\" in str(line):\n",
    "            continue\n",
    "        td = line.findAll('td')\n",
    "        try : \n",
    "            for key in dico.keys():\n",
    "                df.loc[i, dico[key]] = td[key].text\n",
    "            i += 1\n",
    "        except : \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some text replacements and cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~df[\"missed fg1\"].str.contains(\"%\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace({\"\\n\" : \"\", \"\" : \"0\", '\\xa0' : \"0\"}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we calculate the number of missed fg and ft \n",
    "def parse_str(x):\n",
    "    temp = x.split(\"/\")\n",
    "    if len(temp) == 2:\n",
    "        return int(temp[1]) - int(temp[0])\n",
    "    else : \n",
    "        return(x)\n",
    "    \n",
    "df[\"missed fg1\"] = df[\"missed fg1\"].map(lambda x : parse_str(x))\n",
    "df[\"missed fg2\"] = df[\"missed fg2\"].map(lambda x : parse_str(x))\n",
    "df[\"missed ft\"] = df[\"missed ft\"].map(lambda x : parse_str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have clean, good formatted data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>missed fg1</th>\n",
       "      <th>missed fg2</th>\n",
       "      <th>missed ft</th>\n",
       "      <th>rebonds</th>\n",
       "      <th>assists</th>\n",
       "      <th>steals</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>blocks</th>\n",
       "      <th>shots rejected</th>\n",
       "      <th>fouls committed</th>\n",
       "      <th>fouls drown</th>\n",
       "      <th>PIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   points  missed fg1  missed fg2  missed ft  rebonds  assists  steals  \\\n",
       "0    27.0         2.0         3.0        1.0      4.0      4.0     0.0   \n",
       "1    14.0         1.0         5.0        2.0      6.0      2.0     2.0   \n",
       "2    27.0         4.0         3.0        1.0      8.0      5.0     3.0   \n",
       "3    28.0         2.0         2.0        0.0      9.0      4.0     0.0   \n",
       "4    12.0         3.0         4.0        0.0      7.0      3.0     1.0   \n",
       "\n",
       "   turnovers  blocks  shots rejected  fouls committed  fouls drown   PIR  \n",
       "0        2.0     0.0             0.0              1.0          6.0  32.0  \n",
       "1        2.0     1.0             0.0              2.0          8.0  21.0  \n",
       "2        1.0     0.0             3.0              0.0         10.0  41.0  \n",
       "3        3.0     0.0             0.0              2.0          3.0  35.0  \n",
       "4        3.0     0.0             0.0              1.0          6.0  18.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st idea :\n",
    "solve a linar equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df.drop(\"PIR\", axis=1).iloc[:df.shape[1]-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = df[\"PIR\"][:df.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.,  21.,  41.,  35.,  18.,  30.,  19.,  28.,  14.,  32.,  36.,\n",
       "        26.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(df.drop(\"PIR\", axis=1).iloc[:df.shape[1]-1, :], np.linalg.solve(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the right solution. \n",
    "\n",
    "This approach could take a while if we had a bigger system and we could have more than 1 solution if we had colinearity between our observations. We can try to approximate the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd idea : use the least square approximation (we use a linear regression for this) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(df.drop(\"PIR\", axis=1), df[\"PIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all equations are verified ? : True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(\"all equations are verified ? :\", all(np.round(np.dot(df.drop(\"PIR\", axis=1), lr.coef_), 1) == df[\"PIR\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We found the right solution but we were lucky that the the equation was linear. \n",
    "\n",
    "If it was not the case, we could have tried a regression with polynomial features : sklearn.preprocessing.PolynomialFeatures(). We also could have tried exponential / logarithmic features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "**Read the following paper and express your thoughts, ideas, suggestions and/or questions about how the mentioned techniques and applications can be useful to Pricesearcher.**\n",
    "\n",
    "I believe Text Mining is a central problematic at PriceSearcher as the website compares different string patterns from other commercial websites to get information (prices, reviews, marks...). Managing all the different ways that websites enter their information can be very painful.\n",
    "\n",
    "\n",
    "Moreover, trying to get all the information manually about all the products (millions I believe) is nearly impossible. The best way is to find an automatic way to scrap, extract and classify the informations. \n",
    "\n",
    "\n",
    "Some techniques quoted in the article could be interesting for PriceSearcher :\n",
    "\n",
    "\n",
    "- **Information Retrieval** : Let's say you want to get information of a given product from a page of a commercial website that you scrapped. The idea is to automatically detect the information we want to get from the page : the price, the name, the reference from a HTML scraped-page. First, we need labelled data : we can do that manually or from a regex based method that we will manually check. Then we can use a word embedding model like **word2vec** to get a  matrix describing each sentence / each word of our document. Finally, we can build a multi-task classification on a Neural Network (an LSTM can do the job or even a Convolutional Neural Network). \n",
    "\n",
    "\n",
    "- **Product Matching** : I guess PriceSearcher have a catalog of all the available products. it can be complicated to match products to users' inputs. In that case we can use Fuzzy Search that will match the inputs to the most probable products. \n",
    "\n",
    "\n",
    "- **Web Crawler** : The website has a \"Reviews\" and a \"Buying Guides\" categories. We must find the corresponding articles by scraping the internet. Then to get the right articles, we need to build a Document Classification.  To do that we can first build features : Tokenization, POS TAG, TFIDF and other features that seem relevant and then build a Supervised Machine Learning algorithm. In case we do not have labelled data, we can scrap a whole different set of articles and perform a Document Clustering. Then, we could find the cluster of articles and then build a supervised model on top of that to gain precision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
